{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a09cb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import tensorflow \n",
    "from tensorflow import keras\n",
    "\n",
    "# fonctions de récupération et préparation des données\n",
    "import traintestsplit as tts\n",
    "from words_txt_to_df import txt_to_df\n",
    "from nettoyage_fichiers import clean_data, error_image\n",
    "from harmonisation import harmony_clean\n",
    "from keep_n_chars import max_n_chars\n",
    "\n",
    "# Générateur de batchs\n",
    "from  generator_rnn import DatasetGenerator\n",
    "\n",
    "# Modèlisation\n",
    "import tensorflow  \n",
    "import string\n",
    "\n",
    "# Modèlisation\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras.layers import  Input, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, LSTM, Dense\n",
    "\n",
    "from tensorflow.keras.layers import  MaxPooling2D, Dropout, Bidirectional\n",
    "\n",
    "from tensorflow.keras.layers import  Lambda, Reshape\n",
    "from tensorflow import squeeze\n",
    "\n",
    "# Loss\n",
    "from tensorflow.keras.backend import ctc_batch_cost\n",
    "\n",
    "# Décodage\n",
    "import tensorflow.keras.backend as K\n",
    "# Décodage\n",
    "import rnn_pred \n",
    "\n",
    "# Reproductibilité\n",
    "from numpy.random import seed\n",
    "seed(64)\n",
    "from tensorflow import random\n",
    "random.set_seed(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024e2a5",
   "metadata": {},
   "source": [
    "# Préparation des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c102572d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture de words.txt et transformation en dataframe\n",
      "Suppression des erreurs de lecture d'image du df\n",
      "Erreur de lecture sur l'image: a01-117-05-02.png\n",
      "Erreur de lecture sur l'image: r06-022-03-05.png\n",
      "génération d'un dataframe contenant la répartition du dataset [line_id,set]\n",
      "Split des données\n",
      "Préparation des données\n",
      "Construction du modèle\n"
     ]
    }
   ],
   "source": [
    "print(\"Lecture de words.txt et transformation en dataframe\") \n",
    "df_words = txt_to_df('words.txt')\n",
    "\n",
    "print(\"Suppression des erreurs de lecture d'image du df\")\n",
    "df_words = clean_data(df_words)\n",
    "\n",
    "print(\"génération d'un dataframe contenant la répartition du dataset [line_id,set]\")\n",
    "df_tts = tts.text_to_splitDataframe()\n",
    "\n",
    "print(\"Split des données\")\n",
    "trainset, testset, validationset = tts.split_data(df_tts, df_words)\n",
    "\n",
    "\n",
    "# Variables utiles\n",
    "TARGET_SIZE = (128,32)\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 25\n",
    "MAX_LENGTH = 21\n",
    "\n",
    "\n",
    "\n",
    "# Suppression des mots plus longs que MAX_LENGTH \n",
    "trainset = max_n_chars(trainset, MAX_LENGTH)\n",
    "testset = max_n_chars(testset, MAX_LENGTH)\n",
    "validationset = max_n_chars(validationset, MAX_LENGTH)\n",
    "    \n",
    "# Préparation des données\n",
    "print(\"Préparation des données\")\n",
    "    \n",
    "# Tranformation des images par lots\n",
    "train_generator = DatasetGenerator(dataframe=trainset,\n",
    "                                    directory=\"\",\n",
    "                                    x_col = \"data_path\",\n",
    "                                    y_col = \"transcript\",\n",
    "                                    targetSize = TARGET_SIZE,\n",
    "                                    nb_canaux = 1, # images grayscale par défaut\n",
    "                                    batchSize = BATCH_SIZE,\n",
    "                                    shuffle = False,\n",
    "                                    max_y_length = MAX_LENGTH)\n",
    "\n",
    "# Idem pour le jeu de validation\n",
    "valid_generator = DatasetGenerator(dataframe=validationset,\n",
    "                                    x_col = \"data_path\",\n",
    "                                    y_col = \"transcript\", \n",
    "                                    targetSize = TARGET_SIZE,  \n",
    "                                    shuffle = False, \n",
    "                                    max_y_length = MAX_LENGTH)\n",
    "\n",
    "# Et le jeu de test\n",
    "test_generator = DatasetGenerator(dataframe=testset,\n",
    "                                    x_col = \"data_path\",\n",
    "                                    y_col = \"transcript\", \n",
    "                                    targetSize = TARGET_SIZE,  \n",
    "                                    shuffle = False, \n",
    "                                    max_y_length = MAX_LENGTH)\n",
    "    \n",
    "print(\"Construction du modèle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29dc810",
   "metadata": {},
   "source": [
    "# Construction du modèle et entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af9d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction de la couche CTC\n",
    "class CTCLayer(tensorflow.keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred, y_lengths):\n",
    "        # Calcul de la loss value et ajouter à la couche avec fonction 'self.add_loss()'\n",
    "        batch_len = tensorflow.cast(tensorflow.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tensorflow.cast(tensorflow.shape(y_pred)[1], dtype=\"int64\")       \n",
    "\n",
    "        input_length = input_length * tensorflow.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = y_lengths * tensorflow.ones(shape = [1], dtype=\"int64\")\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # Retourner seulement les prédiction calculées au final\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b3bed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_rnn(target_size):\n",
    "    \"\"\"\n",
    "    La fonction build_model_rnn construit un modèle rnn pour obtenir la transcription des écritures manuscrites sur une image.\n",
    "    Paramètres :\n",
    "        target_size : tuple correspondant aux dimensions de l'image souhaitées\n",
    "    Renvoie:\n",
    "        probabilités pour chaque classe\n",
    "    \"\"\"\n",
    "    # Inputs\n",
    "    inputs_data = Input(shape = (target_size[1],target_size[0], 1), name = 'input_im', dtype = 'float32')\n",
    "    labels = Input(shape = (None,), name = 'labels', dtype = 'float32')\n",
    "    y_lengths = Input(name = 'label_length', shape = (None,), dtype = 'int64')\n",
    "    \n",
    "    # CNN\n",
    "    x = Conv2D(filters=64, kernel_size=(9,9),strides=(1,1), padding=\"same\", name = 'conv_1')(inputs_data)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=128, kernel_size=(5,5), strides=(1,1), padding=\"valid\", name = 'conv_2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2), name = 'pool2')(x)\n",
    "    \n",
    "    \n",
    "    x = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding=\"valid\", name = 'conv_3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    output_cnn = MaxPooling2D(pool_size=(2,2), name = 'max_pool2')(x)\n",
    "    \n",
    "    # reshape to enter RNN\n",
    "    x = Reshape((1,output_cnn.shape[2],-1))(output_cnn)\n",
    "    reshape_cnn = Lambda(lambda x: squeeze(x, 1))(x)\n",
    "    \n",
    "    # Couche dense \n",
    "    dense = Dense(256, name = 'dense_1')(reshape_cnn)\n",
    "    dense = Activation(\"relu\")(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    \n",
    "    # RNN\n",
    "    blstm = Bidirectional(LSTM(64, activation='relu', return_sequences=True, dropout=0.2,\n",
    "                               name=\"blstm1\"))(dense)\n",
    "    blstm2 = Bidirectional(LSTM(64, activation='relu', return_sequences=True, dropout=0.2,\n",
    "                               name=\"blstm2\"))(blstm)\n",
    "    \n",
    "    # output layer\n",
    "    y_pred = Dense(len(list(string.printable[:-17]))+1, activation='softmax', name=\"dense\")(blstm2)\n",
    "    \n",
    "    # ctc layer pour calcul de la CTC loss à chaque step\n",
    "    output_ctc = CTCLayer(name=\"ctc_batch_cost\")(labels, y_pred, y_lengths)\n",
    "    \n",
    "    # Définission du modèle\n",
    "    model = Model(inputs=[inputs_data, labels, y_lengths], outputs=output_ctc, name=\"rnn\")\n",
    "    \n",
    "    # compiler le model\n",
    "    model.compile(optimizer=tensorflow.keras.optimizers.Adam())\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffda6d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "WARNING:tensorflow:Layer blstm1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer blstm1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer blstm1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer blstm2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer blstm2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer blstm2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 14:17:30.605445: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-16 14:17:30.605525: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_im (InputLayer)           [(None, 32, 128, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 32, 128, 64)  5248        input_im[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 128, 64)  256         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 128, 64)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 28, 124, 128) 204928      activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 124, 128) 512         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 28, 124, 128) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 14, 62, 128)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 12, 60, 128)  147584      pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 12, 60, 128)  512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 12, 60, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)        (None, 6, 30, 128)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 30, 768)   0           max_pool2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 30, 768)      0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30, 256)      196864      lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 30, 256)      0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 30, 256)      1024        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 30, 256)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 30, 128)      164352      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 128)      98816       bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "labels (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30, 84)       10836       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc_batch_cost (CTCLayer)       (None, 30, 84)       0           labels[0][0]                     \n",
      "                                                                 dense[0][0]                      \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 830,932\n",
      "Trainable params: 829,780\n",
      "Non-trainable params: 1,152\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Entrainement\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 14:17:30.879805: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-16 14:17:30.879919: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-16 14:17:31.959890: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 [==============================] - ETA: 0s - loss: 14.9801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 14:57:42.250894: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 [==============================] - 2479s 5s/step - loss: 14.9801 - val_loss: 13.1990\n",
      "Epoch 2/25\n",
      "534/534 [==============================] - 2490s 5s/step - loss: 12.3472 - val_loss: 11.7463\n",
      "Epoch 3/25\n",
      "534/534 [==============================] - 2454s 5s/step - loss: 11.2781 - val_loss: 10.8213\n",
      "Epoch 4/25\n",
      "534/534 [==============================] - 2458s 5s/step - loss: 12.1784 - val_loss: 13.4000\n",
      "Epoch 5/25\n",
      "534/534 [==============================] - 2454s 5s/step - loss: 11.1045 - val_loss: 10.5415\n",
      "Epoch 6/25\n",
      "534/534 [==============================] - 2479s 5s/step - loss: 10.6001 - val_loss: 11.9799\n",
      "Epoch 7/25\n",
      "534/534 [==============================] - 2466s 5s/step - loss: 10.2285 - val_loss: 12.1380\n",
      "Epoch 8/25\n",
      "534/534 [==============================] - 2454s 5s/step - loss: 9.8836 - val_loss: 10.3196\n",
      "Epoch 9/25\n",
      "534/534 [==============================] - 2469s 5s/step - loss: 9.6341 - val_loss: 9.4313\n",
      "Epoch 10/25\n",
      "534/534 [==============================] - 2448s 5s/step - loss: 9.3746 - val_loss: 9.2738\n",
      "Epoch 11/25\n",
      "534/534 [==============================] - 2463s 5s/step - loss: 9.1526 - val_loss: 9.9605\n",
      "Epoch 12/25\n",
      "534/534 [==============================] - 2449s 5s/step - loss: 8.9372 - val_loss: 12.7889\n",
      "Epoch 13/25\n",
      "534/534 [==============================] - 2464s 5s/step - loss: 8.8831 - val_loss: 10.2236\n",
      "Epoch 14/25\n",
      "534/534 [==============================] - 2459s 5s/step - loss: 8.8496 - val_loss: 26.4843\n",
      "Epoch 15/25\n",
      "534/534 [==============================] - 2453s 5s/step - loss: 8.9141 - val_loss: 13.2088\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 16/25\n",
      "534/534 [==============================] - 2465s 5s/step - loss: 8.3637 - val_loss: 8.5221\n",
      "Epoch 17/25\n",
      "534/534 [==============================] - 2454s 5s/step - loss: 8.1974 - val_loss: 8.3582\n",
      "Epoch 18/25\n",
      "534/534 [==============================] - 2469s 5s/step - loss: 8.1047 - val_loss: 8.3493\n",
      "Epoch 19/25\n",
      "534/534 [==============================] - 2447s 5s/step - loss: 8.0274 - val_loss: 8.4952\n",
      "Epoch 20/25\n",
      "534/534 [==============================] - 2462s 5s/step - loss: 7.9775 - val_loss: 11.3745\n",
      "Epoch 21/25\n",
      "534/534 [==============================] - 2447s 5s/step - loss: 7.9468 - val_loss: 8.1625\n",
      "Epoch 22/25\n",
      "534/534 [==============================] - 2457s 5s/step - loss: 7.8903 - val_loss: 8.2811\n",
      "Epoch 23/25\n",
      "534/534 [==============================] - 2460s 5s/step - loss: 7.8203 - val_loss: 8.1943\n",
      "Epoch 24/25\n",
      "534/534 [==============================] - 2454s 5s/step - loss: 7.7870 - val_loss: 8.3442\n",
      "Epoch 25/25\n",
      "534/534 [==============================] - 2477s 5s/step - loss: 7.7370 - val_loss: 8.1242\n"
     ]
    }
   ],
   "source": [
    "rnn = build_model_rnn(TARGET_SIZE)\n",
    "print(\"Entrainement\")\n",
    "current_pred = keras.models.Model(rnn.get_layer(name=\"input_im\").input, rnn.get_layer(name=\"dense\").output)\n",
    "callbacks = [tensorflow.keras.callbacks.ModelCheckpoint(filepath = 'rnn4.weights.h5', \n",
    "                                                        monitor = 'val_loss', \n",
    "                                                        mode = 'min',\n",
    "                                                        save_best_only=True), \n",
    "             tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                          patience=5,\n",
    "                                                          factor=0.1,\n",
    "                                                          verbose=2,\n",
    "                                                          mode='min')]\n",
    "history = rnn.fit(train_generator,\n",
    "                  steps_per_epoch = len(trainset)//train_generator.batchSize,\n",
    "                  validation_data = valid_generator,\n",
    "                  validation_steps = len(validationset)//valid_generator.batchSize,\n",
    "                  epochs = EPOCHS, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e107d2e5",
   "metadata": {},
   "source": [
    "# Prédictions et évaluation sur le jeu de données test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8615dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prédictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_path</th>\n",
       "      <th>predict_1</th>\n",
       "      <th>predict_2</th>\n",
       "      <th>predict_3</th>\n",
       "      <th>predict_4</th>\n",
       "      <th>predict_5</th>\n",
       "      <th>transcript</th>\n",
       "      <th>transcript_is_pred1</th>\n",
       "      <th>transcript_in_top5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/words/m01/m01-049/m01-049-00-00.png</td>\n",
       "      <td>He</td>\n",
       "      <td>he</td>\n",
       "      <td>te</td>\n",
       "      <td>Hhe</td>\n",
       "      <td>be</td>\n",
       "      <td>He</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/words/m01/m01-049/m01-049-00-01.png</td>\n",
       "      <td>1e</td>\n",
       "      <td>se</td>\n",
       "      <td>1ele</td>\n",
       "      <td>le</td>\n",
       "      <td>1ae</td>\n",
       "      <td>rose</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/words/m01/m01-049/m01-049-00-02.png</td>\n",
       "      <td>fice</td>\n",
       "      <td>fice</td>\n",
       "      <td>fie</td>\n",
       "      <td>fie</td>\n",
       "      <td>fire</td>\n",
       "      <td>from</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/words/m01/m01-049/m01-049-00-03.png</td>\n",
       "      <td>In</td>\n",
       "      <td>Is</td>\n",
       "      <td>bn</td>\n",
       "      <td>bs</td>\n",
       "      <td>hn</td>\n",
       "      <td>his</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/words/m01/m01-049/m01-049-00-04.png</td>\n",
       "      <td>hertes</td>\n",
       "      <td>herted</td>\n",
       "      <td>herte</td>\n",
       "      <td>herates</td>\n",
       "      <td>herated</td>\n",
       "      <td>breakfast-nook</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  data_path predict_1 predict_2 predict_3  \\\n",
       "0  data/words/m01/m01-049/m01-049-00-00.png        He        he        te   \n",
       "1  data/words/m01/m01-049/m01-049-00-01.png        1e        se      1ele   \n",
       "2  data/words/m01/m01-049/m01-049-00-02.png      fice      fice       fie   \n",
       "3  data/words/m01/m01-049/m01-049-00-03.png        In        Is        bn   \n",
       "4  data/words/m01/m01-049/m01-049-00-04.png    hertes    herted     herte   \n",
       "\n",
       "  predict_4 predict_5      transcript transcript_is_pred1 transcript_in_top5  \n",
       "0       Hhe        be              He                True               True  \n",
       "1        le       1ae            rose               False              False  \n",
       "2       fie      fire            from               False              False  \n",
       "3        bs        hn             his               False              False  \n",
       "4   herates   herated  breakfast-nook               False              False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluation\n",
    "print(\"prédictions\")\n",
    "rnn.load_weights('rnn4.weights.h5')\n",
    "predictions = rnn.predict(test_generator)\n",
    "pred_key = rnn_pred.pred_top5(predictions, MAX_LENGTH)\n",
    "pred_words = rnn_pred.df_bilan_top5(testset, pred_key)\n",
    "\n",
    "pred_words['transcript'] = testset.transcript\n",
    "pred_words['transcript_is_pred1'] = None\n",
    "for i in range(pred_words.shape[0]):\n",
    "    pred_words.transcript_is_pred1[i] = evaluation.transcript_in_pred1(pred_words, i)\n",
    "\n",
    "pred_words['transcript_in_top5'] = None\n",
    "for i in range(pred_words.shape[0]):\n",
    "    pred_words.transcript_in_top5[i] = evaluation.transcript_in_top5(pred_words, i)\n",
    "pred_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed6edafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy top 5: False    0.577032\n",
      "True     0.422968\n",
      "Name: transcript_in_top5, dtype: float64\n",
      "accuracy top 1: False    0.67399\n",
      "True     0.32601\n",
      "Name: transcript_is_pred1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy top 5:\", pred_words[\"transcript_in_top5\"].value_counts(normalize = True))\n",
    "print(\"accuracy top 1:\", pred_words[\"transcript_is_pred1\"].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e43a7267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne CER sur pred 1:  0.4806142143505904\n"
     ]
    }
   ],
   "source": [
    "mean_cer_pred1 = pred_words.apply(evaluation.cer, axis = 1).mean()\n",
    "print(\"Moyenne CER sur pred 1: \", mean_cer_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1d6276",
   "metadata": {},
   "source": [
    "**Les résultats sur le test sans restriction sur la longueur des mots satisfaisant, nous sommes proches de nos résultats avec les restrictions à 10 caractères. Le test a été effectué sur 25 epochs, mais il semblerait qu'il aurait été plus bénéfique d'entraîner le modèle sur un nombre d'epoch plus important.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b7d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
